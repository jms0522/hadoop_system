# 🛠️ Hadoop & Spark 기반의 데이터 파이프라인 구축 프로젝트

이 프로젝트는 Hadoop과 Spark를 사용하여 **배치 파이프라인**과 **스트리밍 파이프라인**을 처리하고 분석할 수 있는 환경을 구축하는 것을 목표로 합니다. 대용량 데이터의 효율적인 처리와 실시간 데이터 스트리밍 분석을 통해 비즈니스 인사이트를 도출합니다.

<p align="center">
  <img src="https://media.giphy.com/media/usXZmmgP9Z7kf39fnq/giphy.gif" width="480" height="480" />
</p>
<p align="center">
  <a href="https://giphy.com/gifs/pudgypenguins-data-engineering-doesnt-lie-usXZmmgP9Z7kf39fnq"></a>
</p>

## 📋 프로젝트 개요

- **배치 파이프라인**: 정해진 주기에 따라 대량의 데이터를 일괄 처리
- **스트리밍 파이프라인**: 실시간으로 데이터가 수집되고 처리

이 프로젝트는 두 가지 파이프라인을 동시에 운영하여 데이터를 수집, 저장, 처리, 분석하는 환경을 제공합니다. 

## 🚀 주요 기능

- **Hadoop 기반 배치 처리**: HDFS에 저장된 대용량 데이터를 Spark로 처리
- **Spark 스트리밍**: 실시간 데이터 스트리밍 처리 및 분석
- **데이터 시각화**: 분석된 데이터를 다양한 시각화 도구로 시각화
- **유연한 확장성**: 대용량 데이터를 처리할 수 있는 확장 가능한 환경 구축

## 🛠️ 사용된 기술 스택

- **Apache Hadoop**: 분산 스토리지 및 데이터 처리
- **Apache Spark**: 실시간 데이터 처리 및 분석
- **Kafka**: 스트리밍 데이터 수집
- **HDFS**: 분산 파일 시스템
- **YARN**: 자원 관리 및 클러스터 관리

# 🖥️ 설치 및 실행 방법

1. 환경 설정

	1.	Hadoop 및 Spark를 설치합니다.
	2.	Kafka 클러스터를 설정합니다.
	3.	프로젝트 코드를 클론합니다.

     git clone https://github.com/jms0522/hadoop_system.git
     cd hadoop_system
   
# 📈 결과 분석 및 시각화

분석된 데이터는 notebooks/ 디렉토리에서 Jupyter Notebook을 통해 시각화할 수 있습니다. 다양한 시각화 도구를 활용해 데이터 인사이트를 도출합니다.

📞 문의

프로젝트에 대한 문의 사항이 있으시면 [이메일](jiseo33668@gmail.com)로 연락주세요.
